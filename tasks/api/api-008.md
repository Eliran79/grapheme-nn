---
id: api-008
title: Define Agency and Goal System Traits (Phase 5)
status: done
priority: low
tags:
- api
- cognitive
- agency
dependencies:
- api-005
- api-007
assignee: developer
created: 2025-12-05T22:06:57.112328270Z
estimate: ~
complexity: 5
area: api
---

# Define Agency and Goal System Traits (Phase 5)

## Context
Autonomous goal formation and pursuit. Without agency, GRAPHEME is purely reactive - it responds to inputs but cannot formulate its own objectives, plan to achieve them, or adapt when plans fail.

**Gap Analysis**: Without agency, GRAPHEME cannot:
- Generate its own goals
- Plan multi-step action sequences
- Adapt when plans fail
- Balance exploration vs exploitation
- Maintain persistent intentions

**Alignment Note**: Agency involves goal-directed behavior. Careful design needed to ensure goals remain aligned with user intentions.

## Objectives
- Define trait for autonomous goal management
- Enable hierarchical goal decomposition
- Support planning and replanning
- Integrate with world model for simulation

## Tasks
- [ ] Define `Goal` and `GoalHierarchy` types
- [ ] Define `Agent` struct with goals/values/drives
- [ ] Define `Agency` trait
- [ ] Define planning and replanning
- [ ] Create `grapheme-agent` crate skeleton

## Acceptance Criteria
✅ **Goal Management:**
- Can formulate goals from situations
- Supports goal hierarchies (subgoals)
- Can prioritize competing goals

✅ **Planning:**
- Can generate action sequences
- Can simulate plans before execution
- Can detect and recover from failures

✅ **Adaptation:**
- Replans when blocked
- Learns from failed plans
- Balances exploration/exploitation

## Technical Notes

### Core Structures
```rust
pub struct Goal {
    pub id: GoalId,
    pub description: Graph,       // What to achieve
    pub priority: f32,
    pub deadline: Option<Timestamp>,
    pub subgoals: Vec<GoalId>,
    pub status: GoalStatus,
}

pub enum GoalStatus {
    Pending,
    Active,
    Achieved,
    Failed(String),
    Abandoned,
}

pub struct GoalHierarchy {
    pub goals: HashMap<GoalId, Goal>,
    pub root_goals: Vec<GoalId>,
}

pub struct Agent {
    pub goals: GoalHierarchy,
    pub values: ValueFunction,    // What matters
    pub drives: Vec<Drive>,       // Curiosity, efficiency, etc.
    pub current_plan: Option<Plan>,
}

pub struct Plan {
    pub goal: GoalId,
    pub actions: Vec<Graph>,
    pub expected_states: Vec<Graph>,
    pub contingencies: HashMap<Failure, Plan>,
}

pub enum Drive {
    Curiosity { strength: f32 },
    Efficiency { strength: f32 },
    Safety { strength: f32 },
    Helpfulness { strength: f32 },
}
```

### Trait Definition
```rust
pub trait Agency: Send + Sync {
    /// Generate goal from current situation
    fn formulate_goal(&self, situation: &Graph) -> Goal;

    /// Decompose goal into subgoals
    fn decompose(&self, goal: &Goal, world: &dyn WorldModeling) -> Vec<Goal>;

    /// Create plan to achieve goal
    fn plan(&self, goal: &Goal, world: &dyn WorldModeling) -> Result<Plan, PlanError>;

    /// Execute next action in plan
    fn act(&mut self, world: &mut dyn WorldModeling) -> Action;

    /// Adapt when plan fails
    fn replan(&mut self, failure: &Failure, world: &dyn WorldModeling) -> Result<Plan, PlanError>;

    /// Decide whether to explore or exploit
    fn explore_or_exploit(&self, uncertainty: &UncertaintyEstimate) -> Strategy;

    /// Update goals based on new information
    fn revise_goals(&mut self, observation: &Graph);

    /// Check if goal is achieved
    fn is_achieved(&self, goal: &Goal, state: &Graph) -> bool;
}
```

### Example: Goal-Directed Behavior
```rust
fn autonomous_session(agent: &mut dyn Agency, world: &mut dyn WorldModeling) {
    // Formulate goal from current situation
    let situation = world.current_state();
    let goal = agent.formulate_goal(&situation);

    // Plan to achieve goal
    match agent.plan(&goal, world) {
        Ok(plan) => {
            // Execute plan
            while !agent.is_achieved(&goal, &world.current_state()) {
                let action = agent.act(world);

                // Check if action failed
                if let Err(failure) = world.execute(&action) {
                    // Replan
                    match agent.replan(&failure, world) {
                        Ok(new_plan) => continue,
                        Err(_) => {
                            // Give up on this goal
                            agent.revise_goals(&situation);
                            break;
                        }
                    }
                }
            }
        }
        Err(e) => {
            // Goal not achievable - reformulate
            agent.revise_goals(&situation);
        }
    }
}
```

### ⚠️ NP-Hard Complexity Warning

**Planning (`plan`, `replan`) - CLASSICAL PLANNING IS NP-HARD to PSPACE**
- Finding optimal action sequences is **NP-hard** for bounded plan length
- General planning is **PSPACE-complete**
- Worst case: O(b^d) where b = branching factor, d = plan depth

**Mitigation Strategy (REQUIRED)**:
1. **Depth-limited search**: Max plan depth = 20 steps
2. **Greedy/heuristic planning**: Not optimal, but polynomial
3. **Timeout enforcement**: Fail if planning > T seconds
4. **Hierarchical decomposition**: Break into subgoals first
5. **Precomputed plan templates**: For common goal patterns

**Complexity Bounds (after mitigation)**:
- Plan search: O(b^d) with d ≤ 20, b limited by world model
- Goal decomposition: O(g · rules) where g = goal complexity
- Replanning: O(plan) for local repairs

**Runtime Safeguards**:
```rust
const MAX_PLAN_DEPTH: usize = 20;
const PLANNING_TIMEOUT: Duration = Duration::from_secs(30);

fn plan(&self, goal: &Goal, world: &dyn WorldModeling) -> Result<Plan, PlanError> {
    if goal.complexity() > MAX_PLAN_DEPTH {
        return Err(PlanError::TooComplex);
    }
    // ... with timeout wrapper
}
```

### Files to Create
- `grapheme-agent/Cargo.toml`
- `grapheme-agent/src/lib.rs`
- `grapheme-agent/src/goal.rs`
- `grapheme-agent/src/planning.rs`
- `grapheme-agent/src/drives.rs`

## Testing
- [ ] Goal formulation produces valid goals
- [ ] Planning generates executable sequences
- [ ] Replanning recovers from failures
- [ ] Goal achievement detection works

## Updates
- 2025-12-05: Task created from AGI gap analysis

## Session Handoff (AI: Complete this when marking task done)
**For the next session/agent working on dependent tasks:**

### Dependencies & Integration
- Depends on: api-005 (WorldModeling), api-007 (MetaCognition)
- Top of dependency chain (no dependents)

### Alignment Considerations
- Goals must be bounded by values
- Drives should be configurable
- Human oversight integration needed